{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "hI1Wk-KnDbtU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *Модель*"
      ],
      "metadata": {
        "id": "hI1Wk-KnDbtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        \"\"\"\n",
        "        Архитектура:\n",
        "        - Слой 1: Сверточный слой (conv1) с 8 фильтрами 3x3, шаг 1, padding 1.\n",
        "        - Слой 2: MaxPooling с ядром 2x2 и шагом 2.\n",
        "        - Слой 3: Сверточный слой (conv2) с 16 фильтрами 3x3, шаг 1, padding 1.\n",
        "        - Слой 4: MaxPooling с ядром 2x2 и шагом 2.\n",
        "        - Полносвязный слой: Выход 10 классов.\n",
        "        \"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward-проход: обработка входных данных через слои.\n",
        "        \"\"\"\n",
        "        x = F.relu(self.conv1(x))  # Первый сверточный слой + активация ReLU\n",
        "        x = self.pool(x)           # MaxPooling\n",
        "        x = F.relu(self.conv2(x))  # Второй сверточный слой + активация ReLU\n",
        "        x = self.pool(x)           # MaxPooling\n",
        "        x = x.view(x.size(0), -1)  # Преобразование вектора в одномерный (flatten)\n",
        "        x = self.fc1(x)            # Полносвязный слой\n",
        "        return x"
      ],
      "metadata": {
        "id": "8TcUcL8PisW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Определяем архитекутуру модели.*\n",
        "\n",
        "*Что за ```nn.Module``` оно наследуется из pytorch и представляет собой набор инструментов для создания и управления архитектурой своей нейронной сети*\n",
        "\n",
        "*Начну с самого начала, ```in_channels=1``` - значит что у нас будут только черно белые изображения, подобное выбранное значение определяет то что у нас будет только один цвет и разве что мы будем менять только ее яркость. Если совсем коротко, то наличие одного канала, говорит нам о том что мы можем управлять только интенсивностью черного цвета*\n",
        "\n",
        "*```num_classes=10``` - является чем то вроде указателен на то сколько классов модель должна различать, в данном случае можно прямо сказать что от 0 до 9, модель должна четко отличать между собой и определять*\n",
        "*Приметивны пример отбора наиболее вероятного варианта моделью `[0.1, 0.05, 0.05, 0.8, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01]` под индексом 3 наибольшая реакция*\n",
        "\n",
        "*```super(CNN, self).__init__()``` инициализиируем вызов функций которые определяли для этого класса ранее, для внедрения нашей последующей конфигруации работы алгоритма и в целом его взаимодействие с аппаратной частью*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "30v75IhIi5Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`nn.Conv2d` - обозночает сверточный слой для работы с двумерными данными*\n",
        "каналы уже разбирали, их 1 штук, дальше `8` - является значением числом ядер или же число значений которое будет излвекаться на выявление признаков.\n",
        "`kernel_size=3` - 3 обозначает 3x3, это диапозон охвата одного ядра который обучается на текущем слое, который сканирует изображение.\n",
        "`stride=1` - шаг ядра, то, с какое расстояние будет преодолевать ядра в пикселях за один ход, в нашем примере, это означает что ядра будут двигаться на 1 пиксель за каждый ход.\n",
        "`padding=1` - добавляет пустых пикселей вокруг изображения, что бы сохранить ее целостность и не налазить никуда"
      ],
      "metadata": {
        "id": "ZS38Lc00qnIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ну по своей сути, получается, что 8 так называемых ядер но по своей сути выступают сканерами, которые имеют размерность 3х3 а благодаря padding реальная их площадь 4х4, поскольку есть невидемое утолщение для сохранения целостности, по stride они ходят за один ход на один пиксель. Оно так же ведет поиски в диапозоне своих 3х3, лишь с учетом дополнительных страхоночных пикселей, оно не составляет 4х4 фактический\n",
        "\n"
      ],
      "metadata": {
        "id": "1PLq7L4LtWmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.MaxPool2d` - если браться за тафталогию, то это является областью максимального пулинга, в котором если говорить грубо то каждое ядро сжымается и в дальнейшем из них с каждого диапозона которые охватили путем прохождения по определенным длинам шагов и массой ядра будут взяты максимальные числа как представители их зоны"
      ],
      "metadata": {
        "id": "al_cK-Aqu3vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*и так `conv2`, здесь, входное количество каналов ровно пропорциально выходному количеству каналов их предыдущего сверточника. Что касатель `16` то это количество ядер или возможно будет менее корректно но легче `сканнеров`, остальное все базовое, диапозон сканнера 3х3, шаг в 1 и защитный слой 1.*"
      ],
      "metadata": {
        "id": "eKQoixXuwKPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`Linear` - ялвяется полносвязным слоем, который выполняет линейное переобразование выходных данных при помощи формулы. На который и передаюутся все значения вместе с количеством классов модели. Является конечной точкой, в котором оно собирает все значения после пулингов и решает, каким числом вероятнее всего является.*"
      ],
      "metadata": {
        "id": "rnyMbNpa0d2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*функция `forward`, является чем то вроде маршрутк, который проводит x - в лице нашей картинки, через все этапы которые мы загатавлевали ранее. Отдельно стоит отметить `Flatten`, поскольку видем впервые, это является подведением итогов, где все признаки суммируются и преобразуются в финальный ответ*"
      ],
      "metadata": {
        "id": "GGb7lleq1-nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    # Устройство для вычислений (CPU/GPU)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Гиперпараметры\n",
        "    learning_rate = 0.001\n",
        "    batch_size = 64\n",
        "    num_epochs = 10\n",
        "\n",
        "    # Загрузка данных MNIST\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transform, download=True)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Инициализация модели, функции потерь и оптимизатора\n",
        "    model = CNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Цикл обучения\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Эпоха [{epoch + 1}/{num_epochs}]\")\n",
        "        for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Forward-проход\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Обратное распространение и обновление весов\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Сохранение обученной модели\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pth\")\n",
        "    print(\"Модель сохранена как 'mnist_cnn.pth'\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "b95kVeKU15tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*обучение и тренировка модели*\n",
        "\n",
        "*на первой страке можем заметить, что программа определяет наличие `cuda` ядер, в простонародии видеокарту, при отсутсвтии, использует возможности процессора, хочу отметить что выглядит достаточно удобно, так как подстраивается само*\n",
        "\n",
        "*что касается гиперпараметров, `learning_rate` - отвечает за скорость обучения, где мы выбрали достаточное малое значение, что бы обучение модель происходило достаточно размеренно и точно, для скорости можно поднять, но потери будут все выше. batch_size - явдяется чем то вроде мультипоточности, количество того сколько алгоритм обрабатывает за одну итерацию можно сказать. num_epochs - определеяет количество того, сколько раз алгоритм пройдет тренировку, значение 10 может показаться большим, но кажется самый среднячок*\n",
        "\n",
        "*загрузка тренировочного датасета от MNIST, это является стандартным набором данных для подобных задач, с числами размерностью 28на28*\n",
        "\n",
        "*следом идем этап инициализации и применение нашей архитектуры, первой стрчокой сразу видем, как в переменную model инициализируем класс `CNN`, с переносом посредством `.to()`, на нужный нам исполнтель в лице процессора либо видекарты в зависимотси от выполненйи условий. Следом идет функция потерь, которая сравнивает предсказания модели с заведомо верными метками используя для задач классификации. Дальше `.Adam`, который автоматическим образом, обновляет веса модели на основе ошибки, Adam автоматически регулирует шаг обновления для каждого веса, посредством переданного ему parameters*\n",
        "\n",
        "*следом идет цикл обучения, который запускается по количеству эпох, этох это полный проход по всему алгоритму обчения*\n",
        "\n",
        "*ну и, сохранение модели в файле (mnist_cnn.pth)*\n",
        "\n"
      ],
      "metadata": {
        "id": "UNjTAXIv3XEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image):\n",
        "    \"\"\"\n",
        "    Принимает изображение (PIL Image), обрабатывает его и возвращает предсказанный класс.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = CNN()\n",
        "    model.load_state_dict(torch.load(\"mnist_cnn.pth\", map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        scores = model(image)\n",
        "        _, prediction = scores.max(1)\n",
        "    return prediction.item()"
      ],
      "metadata": {
        "id": "yqLtXakgAUvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*итак, функция предсказания*\n",
        "\n",
        "*начать стоит с того, что нас встречает определение вычеслительной аппаратуры, в лице видеоядра тобе `CUDA` или же `CPU` процессор, стоит отметить, что очень удобно то что библиотека предоставляет возмность не отходя от кассы провети проврку.*\n",
        "\n",
        "*иницализируем архитекутуру модели в переменную `model`, но пока что она находится без самой обученной модели, мы лишь определили ее архитектуру.*\n",
        "\n",
        "*следом вытиягиваем файл с моделью `mnist_cnn.pth`, которую обучали на предыдущем этапе*\n",
        "\n",
        "*ну и конечно же выбор того на каком аппаратном ускорителе будет работать при помощи `.to(и переменная в которую мы ранее определяли проверку)`*\n",
        "\n",
        "*`.eval()`, является чем то вроде переключателя режима нейронной сети, модели могут работать по разному в зависимости от того мы их обучаем или используем на практике. Если приводить в пример то когда она может пригодиться, то тот же `dropout`, который при обучении модели при достижении определенного придела может обнулить значения нейронов воизбежание переобучения, тут оно нам будет только мешать, при `eval`, мы будем использовать все нейроны которые имеем*\n",
        "\n",
        "*следом, у нас идет предварительная адаптация изображения в лице transform, является чем то вроде процессинга из текста, который оптимизирует и подстраивает под возможности модели*\n",
        "\n",
        "*`transforms.Grayscale(num_output_channels=1),`, преобразует изображение в однокальный формат, что бы изображение было в пределах белого и черного*\n",
        "\n",
        "*`transforms.Resize((28, 28)),`, полученное изображение масштабируется до разрешения 28на28, с этого следует вывод, что модель обучалась на подобных изображениях*\n",
        "\n",
        "*`transforms.ToTensor()`, переобразует в тензор pytorch, что бы работать с числовыми данными подсчитывать вероятности*\n",
        "\n",
        "*`transforms.Normalize((0.5,), (0.5,))`, приводит значения пикселей к одному диапозону*\n",
        "\n",
        "*`transform(image)` - примененние нормализации на изображении*\n",
        "\n",
        "*`unsqueeze(0)` - необходимо, для того что бы модель приняла изображение отправилось в формате одного батча*\n",
        "\n",
        "*`.to(device)` - определение аппаратного ускорителя*\n",
        "\n",
        "*`with torch.no_grad():` - отключение автоматического вычисления градиента. Для чего это нужно? обычно требуется при обучении, но в нашем случае, мы выносим предикт на модели*\n",
        "\n",
        "*`scores = model(image)` - отправка изображения в модель*\n",
        "\n",
        "*`        _, prediction = scores.max(1)`*\n",
        "*    `return prediction.item()` - определяет наиболее вероятное значение из 10 эпох и получается суммарно 100 индексов, поскольку было 10 классов по 10 эпох*"
      ],
      "metadata": {
        "id": "IJXhAZmtBcTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.eval()  # Переключение модели в режим оценки\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    accuracy = float(num_correct) / float(num_samples) * 100\n",
        "    print(f\"Точность: {accuracy:.2f}%\")\n",
        "    model.train()  # Возвращение в режим обучения"
      ],
      "metadata": {
        "id": "VyDYlCVOKzhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Оценка точности модели*\n",
        "\n",
        "*первые две строки уже знакомы нам, `определение аппаратного ускорителя` для обработки и переключение модели в `режим оценки`.*\n",
        "\n",
        "*`num_correct = 0` - счетчик верных предсказаний модели*\n",
        "\n",
        "*`num_samples = 0` - общее количество проверенных примеров*\n",
        "\n",
        "*данные параметры будут использоваться для рассчета точности*\n",
        "\n",
        "\n",
        "*`with torch.no_grad():` - как говорил ранее, отключение автоматического определителя градиентов, позволяет разгрузить память и обеспечивает более быструю работу распознавания*\n",
        "\n",
        "\n",
        "*`for x, y in loader:` - проходит через весь набор данных, `x` - является входным изображением которое мы ранее переопределили в батч, следом идет `y` - в которой метки классов от MNIST, которые мы обучали*\n",
        "\n",
        "*`x, y = x.to(device), y.to(device)` - переносит входные данные и классы (метки) на то же устройство на котором работает модель*\n",
        "\n",
        "*`scores = model(x)` - пропускает входные батчи через модель. Возвращается данные в следующем виде `[1.5, 2.3, 0.7, 4.0, 0.5, 0.1, 0.2, 0.8, 1.0, 0.3]`, где самая максимальная оценка означает самую вероятную*\n",
        "\n",
        "*`_, predictions = scores.max(1)` - возвращает максимальное значение вместе с его индексом, почему не использовали просто max()? в таком случае он бы вернул только само максимальное значение*\n",
        "\n",
        "*`num_correct += (predictions == y).sum()` - сравнивает предсказания модели с классами из MNIST, которые хранились в `y`. Оно накапливает в себе булевые значения*\n",
        "\n",
        "*`num_samples += predictions.size(0)` - возвращает количество примеров в батче*\n",
        "\n",
        "*`accuracy = float(num_correct) / float(num_samples) * 100` - рассчет точности*\n",
        "\n",
        "*`model.train()` - возвращение модели в режим обучения*"
      ],
      "metadata": {
        "id": "fEio1cKBK2Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Обучение модели\n",
        "    model = train_model()\n",
        "\n",
        "    # Тестирование модели\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transform, download=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "id": "naRgcDNvO2bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*запускает процесс сборки модли, если была запущенна как основная программа*\n",
        "\n",
        "*`model = train_model()` - ининциализируется модель в тестовом формате*\n",
        "\n",
        "*Стягиваются датасеты и последним подсчитывается точность модели*"
      ],
      "metadata": {
        "id": "M_3qbe6HQbSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Интерфейс*"
      ],
      "metadata": {
        "id": "ys6PSWgBQ76l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "from model import predict_image  # Импорт функции предсказания из model.py"
      ],
      "metadata": {
        "id": "WpBnAUUZTa8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*инструменты необходимые для воспроизведение интейрфейса и работы с изображениям, а так же функция выношения предикта из скрипта модели*"
      ],
      "metadata": {
        "id": "_TXwfZWhTbyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DrawApp:\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.root.title(\"Digit Recognizer\")\n",
        "\n",
        "        # Canvas для рисования\n",
        "        self.canvas = tk.Canvas(root, width=280, height=280, bg=\"white\")\n",
        "        self.canvas.pack()\n",
        "\n",
        "        # Кнопки\n",
        "        self.button_predict = tk.Button(root, text=\"Recognize\", command=self.recognize)\n",
        "        self.button_predict.pack()\n",
        "\n",
        "        self.button_clear = tk.Button(root, text=\"Clear\", command=self.clear_canvas)\n",
        "        self.button_clear.pack()\n",
        "\n",
        "        # Метка для отображения результата\n",
        "        self.label_result = tk.Label(root, text=\"Draw a digit and press 'Recognize'\")\n",
        "        self.label_result.pack()\n",
        "\n",
        "        # Изображение и инструмент рисования\n",
        "        self.image = Image.new(\"RGB\", (280, 280), \"white\")\n",
        "        self.draw = ImageDraw.Draw(self.image)\n",
        "\n",
        "        # Привязка событий рисования\n",
        "        self.canvas.bind(\"<B1-Motion>\", self.paint)\n",
        "\n",
        "    def paint(self, event):\n",
        "        x, y = event.x, event.y\n",
        "        r = 6  # Размер кисти\n",
        "        self.canvas.create_oval(x - r, y - r, x + r, y + r, fill=\"black\", outline=\"black\")\n",
        "        self.draw.ellipse([x - r, y - r, x + r, y + r], fill=\"black\")\n",
        "\n",
        "    def recognize(self):\n",
        "        # Преобразование изображения в градации серого\n",
        "        gray_image = ImageOps.grayscale(self.image)\n",
        "        result = predict_image(gray_image)  # Вызов функции из model.py\n",
        "        self.label_result.config(text=f\"Recognized digit: {result}\")\n",
        "\n",
        "    def clear_canvas(self):\n",
        "        # Очистка холста и изображения\n",
        "        self.canvas.delete(\"all\")\n",
        "        self.image = Image.new(\"RGB\", (280, 280), \"white\")\n",
        "        self.draw = ImageDraw.Draw(self.image)\n",
        "        self.label_result.config(text=\"Draw a digit and press 'Recognize'\")"
      ],
      "metadata": {
        "id": "Y79JJF0YTW5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*основные настройки мини прилоежния и рисования на ней, вместе с функцией стерки*\n",
        "\n",
        "*их интересного стоит отметить функцию `recognize`*\n",
        "которая как раз таки и применяет функцию для выношения предиктов, предварительно переработав в черно белый формат, при помощи `.grayscale(self.image)`*\n",
        "\n",
        "*следом идет отображение метки при помощи `label_result.config`*"
      ],
      "metadata": {
        "id": "Ct5R6tkGTXkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    root = tk.Tk()\n",
        "    app = DrawApp(root)\n",
        "    root.mainloop()"
      ],
      "metadata": {
        "id": "MkzZj6mPT79T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*инициализация всего скрипта*"
      ],
      "metadata": {
        "id": "ePGUc5JvUw0q"
      }
    }
  ]
}